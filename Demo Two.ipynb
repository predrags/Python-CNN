{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import numpy and keras modules.  We will use the ResNet50 deep neural network model included with Keras to recognize objects and images. \n",
    "\n",
    "Here import the model from Keras applications import ResNet 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next let's create a new instance of the Resnet 50 model by creating a new Resnet 50 object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50.ResNet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load an image by calling Keras' built in image.load image function and passing in the file name. \n",
    "\n",
    "This image is 1,365 pixels square. That's too large for us to process with the neural network. \n",
    "\n",
    "When you feed images into a neural network the size of the image needs to match the number of input nodes in the neural network. For ResNet 50 images we feed into the network need to be 224 pixels by 224 pixels. So we need to resize the image before we can use it. Target Size achieves just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"bay.jpg\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the image to a numpy array:\n",
    "\n",
    "We need to convert the image data into an array of plain numbers. There's a built in  function to do this called image.img to array. This will turn our image into a 3D array. The first two dimensions are the height and width of the image which will be 224 by 224. The third dimension is color.\n",
    "\n",
    "Each pixel in the color image is made up of a red value, a blue value, and a green value. Our array will be three layers deep, with each layer representing how intense the red, green, or blue is. \n",
    "\n",
    "The neural network expects us to pass in an array and multiple images at once. But right now we only have a single image to process. We can fix this by adding a fourth dimension to our array. Basically, we just need to turn this single image into an array of multiple images, with just one element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a forth dimension since Keras expects a list of images:   This will turn our image into a three dimensional array. The first two dimensions are the height and width of the image which will be 224 by 224. The third dimension is color. Fourth dimension turns our one image into multiple images.\n",
    "\n",
    "Axis 0 is the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the input image to the range used in the trained network:\n",
    "\n",
    "Most images you have in your computer represent the red, green, and blue values of each pixel as one byte. That means each value can range from zero to 255. But neural networks work best with small numbers. So we need to normalize the data before we feed it to the neural network.\n",
    "\n",
    "This model has a built in normalization function called preprocess input that will do that for us. We just need to call it and pass in our data. \n",
    "\n",
    "We'll call ResNet 50.preprocessed input and pass in X. \n",
    "\n",
    "Now we are ready to run the normalized data through the neural network and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = resnet50.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the image through the deep neural network to make a prediction:\n",
    "\n",
    "We are ready to run the normalized data and make a prediction. \n",
    "We'll call model.predict and we'll pass in X the image data.\n",
    "\n",
    "This will return a predictions object. The predictions object is a 1,000 element array of floating point numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index zero is the results for the first image.\n",
    "\n",
    "By default, it will give us the top five most likely matches, but if we add in top equals nine, we can get the top nine matches instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = resnet50.decode_predictions(predictions, top=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an image of:\n"
     ]
    }
   ],
   "source": [
    "print(\"This is an image of:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just loop thru predictions and print out the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - seashore: 0.482728 likelihood\n",
      " - lakeside: 0.329963 likelihood\n",
      " - dock: 0.105208 likelihood\n",
      " - breakwater: 0.051779 likelihood\n",
      " - promontory: 0.009503 likelihood\n",
      " - catamaran: 0.004744 likelihood\n",
      " - sandbar: 0.002375 likelihood\n",
      " - trimaran: 0.001249 likelihood\n",
      " - pier: 0.001172 likelihood\n"
     ]
    }
   ],
   "source": [
    "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
    "    print(\" - {}: {:2f} likelihood\".format(name, likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
